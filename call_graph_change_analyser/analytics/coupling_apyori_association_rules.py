# -*- coding: utf-8 -*-
"""coupling_apyori_association_rules.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kS_vHbeBYbOwtIjPe2jgfXQSCoYUmT8S
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
 
drive.mount('/gdrive')
# the project's folder
# %cd '/gdrive/My Drive/callgraphCA'

!ls -la "/gdrive/MyDrive/callgraphCA" #uzh -> zhaw

!pip install apyori
# https://github.com/ymoch/apyori
# https://medium.com/linkit-intecs/apriori-algorithm-in-data-mining-part-2-590d58e0998b

import pandas as pd
import sqlite3
from apyori import apriori
from re import search
from typing import List

import importlib

# works with lists, not pandas, no nan values, apostrophe between values of transaction

# min_support -- The minimum support of relations (float).
# min_confidence -- The minimum confidence of relations (float).
# min_lift -- The minimum lift of relations (float).
# max_length -- The maximum length of the relation (integer).

from coupling_association_rules_utils import *

"""# reload"""

import coupling_association_rules_utils

importlib.reload(coupling_association_rules_utils)
from coupling_association_rules_utils import *

#PATH_TO_ANALYTICS_DB = '/gdrive/My Drive/callgraphCA/JKQtPlotter_analytics.db'
#PATH_TO_ANALYTICS_DB = '/gdrive/My Drive/callgraphCA/glucosio-small.db'
PATH_TO_ANALYTICS_DB = '/gdrive/My Drive/callgraphCA/glucosio-android_analytics.db'

con_graph_db = sqlite3.connect(PATH_TO_ANALYTICS_DB)

cur = con_graph_db.cursor()

"""Test connection"""

sql_statement = """SELECT * FROM git_commit LIMIT 2"""

df = pd.read_sql_query(sql_statement, con_graph_db)

print(df.head())

sql_statement = """SELECT * FROM git_commit LIMIT 10"""

"""# Change coupling analysis

## On commit and file level - distinct
"""

sql_statement = """select 
--commit_hash,
GROUP_CONCAT(distinct("'" || file_name|| "'") )  as files_in_hash
from file_commit
group by commit_hash;"""

records, pruned_records = get_records(con_graph_db, 'files_in_hash', sql_statement, 2)

records[0:12]

rules = apriori(records, min_confidence=0.1, min_support=0.1) # min_lift=0.2, 
rules_list = list(rules)
print(len(rules_list))

for r in rules_list:
  print(r)

rules = apriori(records, min_confidence=0.05, min_support=0.05) # min_lift=0.2, 
rules_list = list(rules)
print(len(rules_list))

for r in rules_list:
  print(r)

"""### pruned records with 2 or more occurrences"""

pruned_records[0:3]

rules = apriori(pruned_records, min_confidence=0.15, min_support=0.15) # min_lift=0.2, 
rules_list = list(rules)
print(len(rules_list))

for r in rules_list:
  print(r)

rules = apriori(pruned_records, min_confidence=0.1, min_support=0.1) # min_lift=0.2, 
rules_list = list(rules)
print(len(rules_list))

for r in rules_list:
  print(r)

df.head(5)



"""### find transactions where this rules happened"""

print(df.loc[df['files_in_hash'] == "'PreferencesActivity.java','LocaleHelper.java'"])

l_elem = ['OverviewFragment.java', 'DatabaseHandler.java']
show_transactions_containing_items(df, l_elem, print_elems=False)

l_elem = ['AddCholesterolActivity', 'AddA1CActivity']
show_transactions_containing_items(df, l_elem, print_elems=False)

l_elems = ["'AddKetoneActivity.java'", "'AddWeightActivity.java'", "'AddGlucoseActivity.java'", "'AddPressureActivity.java'"]
show_transactions_containing_items(df, l_elems, print_elems=False)

for e in l_elems:
    print(e)

"""## On week"""

# apyori.apriori needs apostrophes around each of the values of the transaction
sql_statement = """select
(strftime('%j', date(commit_commiter_datetime, '-3 days', 'weekday 4')) - 1) / 7 + 1 as iso_week,
GROUP_CONCAT("'" || file_name|| "'") as files_in_week
--GROUP_CONCAT(distinct("'" || file_name|| "'") ) as files_in_week
from file_commit
group by (strftime('%j', date(commit_commiter_datetime, '-3 days', 'weekday 4')) - 1) / 7 + 1;"""
df = pd.read_sql_query(sql_statement, con_graph_db)
print(len(df))
records = pd.DataFrame(df['files_in_hash']).stack().groupby(level=0).apply(list).values.tolist()
records = []
for r in records_concats:
    records.append(list(r[0].split(sep=',')))

rules = apriori(records, min_confidence=0.1, min_support=0.1) # min_lift=0.2, 
rules_list = list(rules) # from generator save to list for further analysis
print(len(rules_list))

rules = apriori(records, min_confidence=0.01, min_support=0.01) # min_lift=0.2, 
rules_list = list(rules) # from generator save to list for further analysis
print(len(rules_list))

rules = apriori(records, min_confidence=0.001, min_support=0.001) # min_lift=0.2, 
rules_list = list(rules) # from generator save to list for further analysis
print(len(rules_list))

"""### slide time window"""



rules = apriori(records, min_support=0.2, min_confidence=0.2) #, min_lift=2, min_length=2)
rules_list = list(rules)

print(len(rules_list))

for r in rules_list:
  print(r)















"""#Test stuff"""

from apriori_python import apriori
itemSetList = [['eggs.java', 'bacon.java', 'soup.java'],
                ['eggs.java', 'bacon.java', 'apple.java'],
                ['soup.java', 'bacon.java', 'banana.java'],
                ['soup.java', '', 'bacon.java']
               ]
freqItemSet, rules = apriori(itemSetList, minSup=0.5, minConf=0.5)
print(rules)  
# [[{'beer'}, {'rice'}, 0.6666666666666666], [{'rice'}, {'beer'}, 1.0]]
# rules[0] --> rules[1], confidence = rules[2]